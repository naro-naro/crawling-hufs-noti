{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# 이미지 있는지 확인 (함수 필요하다면)\n",
        "\n",
        "def check_img_tag(html):\n",
        "  soup = BeautifulSoup(html, 'html.parser')\n",
        "  img_tags = soup.find_all('img')\n",
        "  if img_tags:\n",
        "      return True\n",
        "  else:\n",
        "      return False"
      ],
      "metadata": {
        "id": "cc80eAEvphKo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7iN1SvbI_7l-"
      },
      "outputs": [],
      "source": [
        "# 있으면 이미지 함수 호출\n",
        "# 이미지 함수\n",
        "# 이미지 추출 후 일단 날짜로 이미지 이름을 받아오게 해둬서 date를 인자로 받게 했습니다\n",
        "# 날짜인 이유: 파일명으로 쓸 수 없는 기호가 제목에 있으면 에러나고 끊겨서\n",
        "# 병합시 추가 todo : 첫 목록에서 클릭해 들어갈 때 이미지 없는 경우 예외처리, csv column에 이미지 여부 확인하는 열 추가 후 저장여부 확인해주기\n",
        "\n",
        "def get_and_save_img(date):\n",
        "    # 이미지 추출\n",
        "    find_img = driver.find_element(By.CLASS_NAME, 'view-con')\n",
        "    img = find_img.find_elements(By.TAG_NAME, 'img')\n",
        "\n",
        "    # 이미지가 없는 경우 None 반환\n",
        "    if not img:\n",
        "        return None\n",
        "\n",
        "    img_src = img[0].get_attribute('src')\n",
        "\n",
        "    # 이미지 파일 이름 생성\n",
        "    filename = f'{directory}/{date}.jpg'\n",
        "    count = 1\n",
        "    while os.path.exists(filename):\n",
        "        filename = f'{directory}/{date}_{count}.jpg'\n",
        "        count += 1\n",
        "\n",
        "    # 이미지 다운로드\n",
        "    response = requests.get(img_src)\n",
        "\n",
        "    # 이미지를 로컬 파일로 저장\n",
        "    if response.status_code == 200:\n",
        "        with open(filename, 'wb') as f:\n",
        "            f.write(response.content)\n",
        "        print(f\"{date} 이미지를 성공적으로 저장했습니다.\")\n",
        "    else:\n",
        "        print(f\"{date} 이미지를 다운로드할 수 없습니다.\")\n",
        "\n",
        "    return img_src  # 이미지가 있는 경우 이미지 소스 반환"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 텍스트 함수\n",
        "\n",
        "## 글내용 스크랩 함수\n",
        "def get_content():\n",
        "    # 페이지의 소스 가져오기\n",
        "    html_source = driver.page_source\n",
        "\n",
        "    # BeautifulSoup 객체 생성하여 HTML 파싱\n",
        "    soup = BeautifulSoup(html_source, 'html.parser')\n",
        "\n",
        "    # CSS 선택자를 사용하여 내용 추출\n",
        "    content = soup.select_one(\"div.view-con\").get_text(strip=False) if soup.select_one(\"div.view-con\") else ''\n",
        "\n",
        "    # 텍스트 정리\n",
        "    content = content.replace(\"\\t\", \"\").replace('\\xa0', '')\n",
        "\n",
        "    # 글내용 반환\n",
        "    return content\n",
        "\n",
        "\n",
        "## 제목, 날짜 스크랩 함수.\n",
        "def get_titleDate():\n",
        "    # 페이지의 소스 가져오기\n",
        "    html_source = driver.page_source\n",
        "\n",
        "    # BeautifulSoup 객체 생성하여 HTML 파싱\n",
        "    soup = BeautifulSoup(html_source, 'html.parser')\n",
        "\n",
        "    # CSS 선택자를 사용하여 날짜, 제목 추출\n",
        "    title = soup.select_one(\"div.board-view-info div.view-info h2\").get_text(strip=True) if soup.select_one(\"div.board-view-info div.view-info h2\") else ''\n",
        "    date = soup.select_one(\"div.view-info div.view-detail dl.write dd\").get_text(strip=True) if soup.select_one(\"div.view-info div.view-detail dl.write dd\") else ''\n",
        "\n",
        "    # 텍스트 정리\n",
        "    title = title.replace(\"\\t\", \"\").replace('\\xa0', '')\n",
        "\n",
        "    # 제목, 날짜 반환 : ('제목', '날짜') 튜플 형태\n",
        "    return title, date"
      ],
      "metadata": {
        "id": "2GCKHNfX_-99"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 웹 드라이버 및 url 설정\n",
        "# selenium 4\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.service import Service as ChromeService\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "from selenium.webdriver.common.by import By\n",
        "import time\n",
        "from bs4 import BeautifulSoup\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "import os\n",
        "import requests"
      ],
      "metadata": {
        "id": "7zkV_LeFADGB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chrome WebDriver 옵션 설정\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument('--ignore-certificate-errors')\n",
        "\n",
        "# Chrome WebDriver 초기화 및 웹 페이지 열기\n",
        "driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()), options=options)\n",
        "driver.implicitly_wait(5)\n",
        "\n",
        "# 학사공지 홈페이지 접속\n",
        "# url = \"https://www.hufs.ac.kr/hufs/11282/subview.do?enc=Zm5jdDF8QEB8JTJGYmJzJTJGaHVmcyUyRjIxODElMkZhcnRjbExpc3QuZG8lM0Y%3D\"\n",
        "\n",
        "# 장학공지 홈페이지 접속\n",
        "url = \"https://www.hufs.ac.kr/hufs/11283/subview.do\"\n",
        "driver.get(url)\n",
        "\n",
        "# csv에 담아 출력할 DataFrame 생성\n",
        "import pandas as pd\n",
        "df_crawling = pd.DataFrame(columns = ['index', 'date', 'title', 'content'])\n",
        "\n",
        "# 이미지 다운로드 디렉토리 생성 -> 폴더 이름 수정 원할 시 directory명 변경\n",
        "directory = 'test_final'\n",
        "if not os.path.exists(directory):\n",
        "    os.makedirs(directory)"
      ],
      "metadata": {
        "id": "vhGAkWZHdxLZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# index 수집\n",
        "# Selenium으로 페이지의 HTML 소스 가져오기\n",
        "html = driver.page_source\n",
        "\n",
        "# BeautifulSoup 객체 생성하여 HTML 파싱\n",
        "soup = BeautifulSoup(html, 'html.parser')\n",
        "\n",
        "# CSS 선택자로 인덱스 추출\n",
        "elements = soup.select(\"div._fnctWrap table tbody tr:not(.notice) td.td-num\")\n",
        "index_texts = [element.get_text() for element in elements]\n",
        "\n",
        "# 추출한 인덱스 형변환\n",
        "index = int(index_texts[0]) if index_texts else None"
      ],
      "metadata": {
        "id": "E0wu9T7CdzyE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 첫번째 공지 글 클릭\n",
        "# CSS 선택자를 사용하여 공지태그가 아닌 첫 번째 글의 <a> 태그를 찾기\n",
        "first_page = driver.find_element(By.CSS_SELECTOR, \"div.scroll-table tbody tr:not(.notice) a\")\n",
        "\n",
        "# 클릭\n",
        "first_page.click()"
      ],
      "metadata": {
        "id": "H9cFuT3Ed1qj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    try:\n",
        "        title = get_titleDate()[0]\n",
        "        date = get_titleDate()[1]\n",
        "        img_flag = check_img_tag(html)\n",
        "        if img_flag:\n",
        "            get_and_save_img(date)\n",
        "        content = get_content()\n",
        "\n",
        "        # 잘 추출되었는지 확인\n",
        "        print(f\"Index: {index}\")\n",
        "        print(f\"Date: {date}\")\n",
        "        print(f\"Title: {title}\")\n",
        "        print(f\"Content: {content}\")\n",
        "\n",
        "        # 데이터프레임에 추가\n",
        "        new_row = {'index': index, 'date': date, 'title': title, 'content': content}\n",
        "        df_crawling.loc[len(df_crawling)] = new_row\n",
        "\n",
        "        # 인덱스 갱신\n",
        "        index -= 1\n",
        "\n",
        "        # 이전글 클릭\n",
        "        # CSS 선택자를 사용하여 이전글의 <a> 태그를 찾기\n",
        "        previous_page = driver.find_element(By.CSS_SELECTOR, \"main.contents div._fnctWrap div.view-navi dl:first-child dd a\")\n",
        "\n",
        "        # 클릭\n",
        "        previous_page.click()\n",
        "        time.sleep(2)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        break"
      ],
      "metadata": {
        "id": "k5bvIZkm__rd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Selenium WebDriver 종료\n",
        "driver.quit()"
      ],
      "metadata": {
        "id": "IqVFSL4Qd3lq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# csv 파일 export\n",
        "import os\n",
        "df_crawling.to_csv(os.path.join(os.path.expanduser('~'), 'Desktop', 'noti_janghak.csv'), encoding=\"UTF-8\", index=False)"
      ],
      "metadata": {
        "id": "SFX2o87Fd4qC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# csv 형식\n",
        "- 컬럼: 인덱스, 제목, 날짜, 내용\n",
        "  - 만약 내용에 이미지만 있다면\n",
        "    - 로컬에 이미지 저장하기\n",
        "    - csv 파일에는 '이미지만 존재' 출력하기 (추후 텍스트 추출 후 원활한 csv 파일 통합 위함)"
      ],
      "metadata": {
        "id": "G8EHqk-3AYGh"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "azVXR190AFnq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}